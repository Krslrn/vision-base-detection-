{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Function to calculate gaze direction\n",
    "def detect_gaze_direction(landmarks, frame):\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Get eye and iris landmarks (MediaPipe indices)\n",
    "    left_eye_indices = [33, 133]  # Left corner and right corner of the left eye\n",
    "    right_eye_indices = [362, 263]  # Left corner and right corner of the right eye\n",
    "    left_iris_indices = [468]  # Center of the left iris\n",
    "    right_iris_indices = [473]  # Center of the right iris\n",
    "\n",
    "    # Extract coordinates for left eye\n",
    "    left_eye_left = landmarks[left_eye_indices[0]]\n",
    "    left_eye_right = landmarks[left_eye_indices[1]]\n",
    "    left_iris = landmarks[left_iris_indices[0]]\n",
    "\n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    left_eye_left_coords = (int(left_eye_left.x * width), int(left_eye_left.y * height))\n",
    "    left_eye_right_coords = (int(left_eye_right.x * width), int(left_eye_right.y * height))\n",
    "    left_iris_coords = (int(left_iris.x * width), int(left_iris.y * height))\n",
    "\n",
    "    # Extract coordinates for right eye\n",
    "    right_eye_left = landmarks[right_eye_indices[0]]\n",
    "    right_eye_right = landmarks[right_eye_indices[1]]\n",
    "    right_iris = landmarks[right_iris_indices[0]]\n",
    "\n",
    "    right_eye_left_coords = (int(right_eye_left.x * width), int(right_eye_left.y * height))\n",
    "    right_eye_right_coords = (int(right_eye_right.x * width), int(right_eye_right.y * height))\n",
    "    right_iris_coords = (int(right_iris.x * width), int(right_iris.y * height))\n",
    "\n",
    "    # Draw debug points\n",
    "    cv2.circle(frame, left_eye_left_coords, 5, (255, 0, 0), -1)  # Blue\n",
    "    cv2.circle(frame, left_eye_right_coords, 5, (0, 255, 0), -1)  # Green\n",
    "    cv2.circle(frame, left_iris_coords, 5, (0, 0, 255), -1)  # Red\n",
    "\n",
    "    cv2.circle(frame, right_eye_left_coords, 5, (255, 0, 0), -1)  # Blue\n",
    "    cv2.circle(frame, right_eye_right_coords, 5, (0, 255, 0), -1)  # Green\n",
    "    cv2.circle(frame, right_iris_coords, 5, (0, 0, 255), -1)  # Red\n",
    "\n",
    "    # Calculate gaze ratio for left eye\n",
    "    left_eye_width = max(1, left_eye_right_coords[0] - left_eye_left_coords[0])\n",
    "    left_gaze_ratio = (left_iris_coords[0] - left_eye_left_coords[0]) / left_eye_width\n",
    "\n",
    "    # Calculate gaze ratio for right eye\n",
    "    right_eye_width = max(1, right_eye_right_coords[0] - right_eye_left_coords[0])\n",
    "    right_gaze_ratio = (right_iris_coords[0] - right_eye_left_coords[0]) / right_eye_width\n",
    "\n",
    "    # Combine gaze ratios (average for both eyes)\n",
    "    avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2\n",
    "\n",
    "    # Determine gaze direction\n",
    "    if avg_gaze_ratio < 0.35:  # Adjust threshold as needed\n",
    "        return \"Looking Left\"\n",
    "    elif avg_gaze_ratio > 0.65:  # Adjust threshold as needed\n",
    "        return \"Looking Right\"\n",
    "    else:\n",
    "        return \"Looking Forward\"\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty frame.\")\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for a selfie-view display\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Face Mesh\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Detect gaze direction\n",
    "            gaze_direction = detect_gaze_direction(face_landmarks.landmark, frame)\n",
    "\n",
    "            # Display the gaze direction on the frame\n",
    "            cv2.putText(frame, gaze_direction, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Gaze Estimation', frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
